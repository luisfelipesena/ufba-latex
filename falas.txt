# Falas da Apresentação: Desinformação no Meio de Segurança
**Duração:** 30 minutos | **Apresentadores:** Luis Felipe, João, Victoria, Vinicius

---

## **SLIDE 1: Título** (30s - Luis)
"Bom dia/tarde. Hoje apresentaremos nossa análise sobre 'Desinformação no Meio de Segurança' sob uma perspectiva da Ciência da Computação. Sou Luis Felipe, e comigo estão João, Victoria e Vinicius. Nossa apresentação terá duração de 30 minutos, dividida em duas partes principais: primeiros 15 minutos cobrindo fundamentos teóricos e algorítmicos, e os 15 minutos finais analisando o estudo de caso do artigo de Benevenuto e Melo publicado na CACM em 2024 sobre as eleições brasileiras."

---

## **SLIDE 2: Taxonomia Formal de Desinformação** (2 min - Luis)
"Começamos estabelecendo a taxonomia formal. Matematicamente, definimos Desinformação D como o conjunto de mensagens m no espaço informacional M onde a intenção é maliciosa E a veracidade é falsa. Diferenciamos de Misinformação Mi, onde a intenção é benigna mas a veracidade ainda é falsa, e Mal-informação Ma, onde o conteúdo é verdadeiro mas manipulado contextualmente. Esta formalização em teoria dos conjuntos nos permite aplicar algoritmos de classificação com bases matemáticas sólidas, essencial para sistemas automatizados de detecção."

---

## **SLIDE 3: Modelos de Propagação em Grafos Sociais** (2 min - Luis)  
"A propagação segue modelos de difusão em redes. Usamos o modelo SIR adaptado onde S são usuários suscetíveis, I são infectados com desinformação, e R são recuperados. A matriz de transição P governa as probabilidades de mudança de estado. O autovalor dominante λ₁ determina se a desinformação se torna epidêmica. Incorporamos também o modelo de cascata independente com probabilidades p_uv de ativação entre nós adjacentes u e v. Esta abordagem nos permite prever pontos de intervenção ótimos na rede."

---

## **SLIDE 4: Arquitetura de Inteligência de Ameaças** (2 min - João)
"Passando para João, que explicará nossa adaptação do framework MITRE ATT&CK."

"Obrigado Luis. Adaptamos o framework MITRE ATT&CK para desinformação, utilizando o Modelo Diamante que mapeia Adversário-Infraestrutura-Capacidade-Vítima. A Cadeia Cibernética de Ataque adaptada inclui: Reconhecimento do público-alvo, Armamento da narrativa, Entrega via múltiplos canais, Exploração psicológica, Instalação de crenças persistentes, Comando e Controle via coordenação, e Ações finais de influência. Integramos ferramentas de OSINT como Maltego e Shodan para mapear infraestruturas de distribuição. Esta estrutura nos permite categorizar ataques informacionais sistematicamente."

---

## **SLIDE 5: Taxonomia de Táticas e Técnicas Adversariais** (2 min - João)
"Desenvolvemos uma taxonomia detalhada de táticas adversariais. No Armamento, temos fabricação de deepfakes e manipulação contextual. Na Entrega, observamos spam coordenado e fazendas de bots. Para Persistência, vemos disseminação multiplataforma e criação de câmaras de eco. O Comando e Controle opera via canais privados com amplificação de sinais. A Evasão utiliza migração entre plataformas e ofuscação semântica. Esta categorização permite desenvolvimento de contramedidas específicas para cada fase do ataque."

---

## **SLIDE 6: Complexidade Computacional** (2 min - Victoria)
"Victoria agora abordará os aspectos de complexidade computacional."

"Obrigada João. O problema de detecção é NP-difícil para grafos gerais, criando limitações fundamentais. Aplicamos Teoria dos Jogos modelando como max-min onde d são estratégias de detecção e a são estratégias adversariais. O Equilíbrio de Nash representa o ponto onde nenhum jogador melhora unilateralmente. A complexidade de amostragem é O(n log n) para detecção com alta probabilidade, mas isso assume distribuições específicas que nem sempre se verificam em dados reais. Esta análise nos informa sobre limitações teóricas dos algoritmos de detecção."

---

## **SLIDE 7: Pipeline de PLN para Classificação** (2 min - Victoria)
"Nosso pipeline de Processamento de Linguagem Natural segue esta sequência algorítmica: entrada de texto t e modelo pré-treinado M, tokenização, geração de incorporações via M.codificar, extração de características linguísticas e de rede, concatenação dos vetores, classificação via redes neurais, aplicação de softmax para probabilidades, e retorno do argmax. Utilizamos métricas rigorosas: Precisão, Revocação, F1-score, AUC-ROC e Coeficiente de Correlação de Matthews. Esta abordagem multimodal supera métodos baseados apenas em texto."

---

## **SLIDE 8: Modelos Multimodais** (2 min - Victoria)
"Para fusão de modalidades, implementamos tanto Fusão Precoce quanto Tardia. A Precoce concatena características antes da classificação, enquanto a Tardia combina decisões independentes com pesos alfa, beta e gamma. O Mecanismo de Atenção utiliza a fórmula padrão de transformer com normalização pela raiz quadrada da dimensão. Transformers Intermodais detectam inconsistências semânticas entre texto, imagem e áudio, crucial para identificar deepfakes sofisticados."

---

## **SLIDE 9: Criptografia e Verificação de Integridade** (1.5 min - Victoria)
"Para verificação de integridade, empregamos Árvores de Merkle para marcação temporal, onde h = H(H(h1||h2)||H(h3||h4)) cria hashes hierárquicos imutáveis. Provas de Conhecimento Zero permitem verificação sem exposição de dados sensíveis. Assinaturas Digitais RSA e ECDSA garantem autenticação de fonte. Proveniência baseada em Blockchain com contratos inteligentes oferece rastreabilidade completa da cadeia de custódia informacional."

---

## **SLIDE 10: Métricas de Avaliação e Benchmarks** (1.5 min - Vinicius)
"Vinicius apresentará as métricas de avaliação utilizadas."

"Obrigado Victoria. Utilizamos Conjuntos de Dados padrão incluindo FakeNewsNet, LIAR, CoAID e CONSTRAINT-2021. Além da acurácia, implementamos métricas de Justiça usando paridade demográfica DP, Robustez medindo acurácia adversarial sob ataques L-infinito, e Explicabilidade via valores LIME e SHAP. Os Frameworks de Avaliação FEVER, CheckThat! e CLEF fornecem benchmarks comparativos. Esta abordagem multidimensional garante avaliação holística dos sistemas de detecção."

---

## **SLIDE 11: Casos de Uso Globais em Desinformação** (3 min - Vinicius)
"Para contextualizar nossa análise, vejamos casos globais relevantes. A Agência de Pesquisa da Internet russa operou campanhas de interferência nas eleições americanas de 2016 e 2020, alcançando 126 milhões de usuários no Facebook e 20 milhões no Instagram, com investimento de 1.25 milhão de dólares mensais e 3.393 anúncios pagos. Utilizaram técnicas sofisticadas como personas falsas, organização de eventos reais e amplificação artificial, exemplificando perfeitamente os frameworks teóricos que apresentamos."

"O caso SolarWinds/Sunburst, atribuído ao APT29, combinou ataques à cadeia de suprimentos com desinformação sobre atribuição. Comprometeu 18.000 organizações globalmente incluindo Microsoft, FireEye e Cisco, operando por 18 meses sem detecção enquanto disseminava desinformação para minimizar o impacto real."

---

## **SLIDE 12: Casos de Uso Globais em Desinformação (cont.)** (2 min - Vinicius)
"As campanhas anti-vacina demonstram coordenação internacional massiva. O relatório 'Dozen Disinformers' identificou que apenas 12 indivíduos geraram 65% da desinformação anti-vacina global, com movimento coordenado internacional gerando receita estimada em 36 milhões de dólares. Utilizaram técnicas como cherry-picking de estudos científicos, apelos emocionais e teorias conspiratórias."

"Na Guerra da Ucrânia, vemos operações de informação em tempo real com vídeos falsificados profundos de autoridades como Zelensky, narrativas falsas sobre laboratórios biológicos, nazistas e genocídio. RT e Sputnik coordenavam 7 milhões de interações diárias pré-guerra, usando bots multiplataforma, influenciadores pagos e deepfakes, demonstrando a evolução constante das técnicas adversariais."

---

## **SLIDE 13: Metodologia Científica do Estudo** (2 min - Vinicius)
"Agora analisaremos o artigo de Benevenuto e Melo da CACM 2024. O Conjunto de Dados incluiu 1.2 milhões de mensagens WhatsApp e 3 milhões de tweets coletados entre 2018-2022. A Rotulação foi feita em colaboração com verificadores certificados Lupa e Aos Fatos. A Metodologia utilizou abordagem de métodos mistos combinando análise quantitativa e qualitativa. Importante destacar que obtiveram Aprovação do Comitê de Ética em Pesquisa e seguiram considerações éticas rigorosas para dados sensíveis."

---

## **SLIDE 14: Arquitetura Técnica de Coleta** (2 min - Vinicius)
"A coleta técnica foi sofisticada. Para WhatsApp, utilizaram Selenium WebDriver combinado com engenharia reversa da API WhatsApp Web. No Telegram, usaram a API Bot Oficial plus raspagem de canais públicos. Para Twitter, acessaram a API de Pesquisa Acadêmica v2 respeitando limitação de taxa. O Pré-processamento incluiu normalização UTF-8 e desduplicação via MinHash LSH. O Armazenamento utilizou MongoDB para dados não-estruturados e PostgreSQL para metadados estruturados."

---

## **SLIDE 15: Algoritmos de Detecção Implementados** (2 min - Luis)
"Luis retorna para explicar os algoritmos implementados."

"Os algoritmos Baseados em BERT utilizaram ajuste fino do BERTimbau com perda de entropia cruzada. A Análise de Redes implementou PageRank modificado para detecção de influenciadores. A Análise Temporal usou janela deslizante com detecção de rajadas via aproximação de Poisson. Para Detecção de Bots, engenheiraram características como frequência de tweets, entropia temporal e razão seguidor-seguindo. Os Métodos de Conjunto combinaram Floresta Aleatória e Gradient Boosting com ponderação de votos, alcançando robustez superior."

---

## **SLIDE 16: Resultados Quantitativos do Artigo** (2 min - Luis)
"Os resultados quantitativos foram impressionantes. O F1-score do BERTimbau atingiu 0.92 com desvio padrão de ±0.03. A Acurácia de Detecção de Bots foi 0.89 usando Botometer-PT. A Precisão@10 para classificação alcançou 0.87 para conteúdo viral falso. A Correlação Temporal mostrou ρ = 0.74 entre eventos políticos e picos de desinformação. Todos os resultados apresentaram Significância Estatística com p < 0.01 via teste t de Student, demonstrando robustez metodológica."

---

## **SLIDE 17: Análise de Redes - Descobertas Topológicas** (2.5 min - João)
"João analisará as descobertas de rede."

"A análise topológica revelou insights fundamentais. A Propriedade de Mundo Pequeno mostrou diâmetro médio d = 6.2, versus d = 4.1 para redes orgânicas, indicando estruturas artificiais. A Distribuição Lei de Potência P(k) ~ k^(-γ) com γ = 2.8 confirma redes livres de escala. O Coeficiente de Agrupamento C = 0.67 excede significativamente o C = 0.15 esperado para grafos aleatórios. A Detecção de Comunidades via algoritmo de Louvain identificou 847 comunidades distintas. A Assortatividade r = -0.23 indica mistura desassortativa onde hubs conectam com nós pequenos, típico de redes de amplificação artificial."

---

## **SLIDE 18: Comportamento Inautêntico Coordenado** (2.5 min - João)
"Definimos formalmente Comportamento Inautêntico Coordenado como conjunto S de contas onde para todo par si, sj: sobreposição temporal > θt, similaridade de conteúdo > θc, e proximidade de rede > θn. A Detecção utiliza algoritmo baseado em agrupamento de grafos combinado com sincronia temporal. Os Resultados identificaram 1,247 grupos com mais de 5 contas cada, revelando coordenação massiva. Esta formalização matemática permite detecção automatizada de campanhas coordenadas em escala."

---

## **SLIDE 19: Impacto Quantificado na Eleição** (2.5 min - Victoria)
"Victoria quantificará o impacto eleitoral."

"A Estimativa de Alcance utilizou modelo epidemiológico SIR adaptado para propagação informacional. As Métricas de Exposição seguiram E = somatória de vi × Ii × Ti, onde vi são visualizações, Ii influência e Ti tempo. A Inferência Causal empregou design diferença-em-diferenças comparando regiões com diferentes níveis de exposição. O Tamanho do Efeito foi d de Cohen = 0.31 para mudança de intenção de voto, considerado efeito médio. Os Intervalos de Confiança [0.18, 0.44] com 95% de confiança demonstram significância estatística robusta do impacto."

---

## **SLIDE 20: Limitações e Trabalhos Futuros** (2 min - Victoria)
"As limitações incluem: Primeiro, viés de seleção devido à disponibilidade limitada de dados do WhatsApp. Segundo, escopo temporal limitado que não captura evolução de longo prazo. Os Trabalhos Futuros propostos: Primeiro, aprendizado federado para análise preservando privacidade. Segundo, detecção multimodal de deepfake usando GANs adversariais. Terceiro, detecção em tempo real com processamento de fluxo via Apache Kafka e Storm. Estas direções abordam limitações atuais e antecipam desafios futuros."

---

## **SLIDE 21: Conclusões Técnicas** (2 min - Vinicius)
"Para concluir, os algoritmos de Aprendizado de Máquina alcançam desempenho estado-da-arte com F1 > 0.9 para texto português. A análise de redes revela estruturas coordenadas detectáveis computacionalmente. Existe compromisso fundamental entre precisão versus revocação versus interpretabilidade versus justiça. Identificamos necessidade de frameworks multimodais para próxima geração de ataques. Enfatizamos a importância de conjuntos de dados eticamente coletados e pesquisa reproduzível. Este trabalho estabelece base sólida para sistemas de detecção em português brasileiro."

---

## **SLIDE 22: Perguntas e Comentários** (1 min - Todos)
"Obrigado pela atenção. Estamos disponíveis para perguntas e comentários sobre nossa análise técnica da desinformação no contexto de segurança computacional."

---

**DISTRIBUIÇÃO DE TEMPO:**
- Luis Felipe: ~8 minutos (Slides 1, 2, 3, 15, 16)
- João: ~8 minutos (Slides 4, 5, 17, 18)  
- Victoria: ~8 minutos (Slides 6, 7, 8, 9, 19, 20)
- Vinicius: ~9 minutos (Slides 10, 11, 12, 13, 14, 21, 22) 